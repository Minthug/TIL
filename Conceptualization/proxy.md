# Forward Proxy
![](https://velog.velcdn.com/images/minthug94_/post/7103487b-33fb-4619-bd79-559c0ac1c186/image.webp)

Forward Proxy는 클라이언트 가까이에 위치한 프록시 서버로 클라이언트를 
대신해 서버에 요청을 전달해준다.
주로 캐싱을 제공하는 경우가 많아 사용자가 빠른 서비스를 이용할 수 있도록 
돕는다.

## 장점
- ### 캐싱을 통해 빠른 서비스 이용 가능
클라이언트는 서비스의 서버가 아닌 프록시 서버와 소통하게 된다, 그런 
과정에서 여러 클라이언트가 동일한 요청을 보내는 경우 첫 응답을 하며 결과 
데이터를 캐시에 저장한 후, 서버에 재 요청을 보내지 않아도 다른 
클라이언트에게 빠르게 결과를 전달해준다.

- ### 보안
클라이언트에서 프록시 서버를 거친 후 서버에 요청이 도착하기 때문에, 
서버에서 클라이언트 IP 추적이 필요한 경우 클라이언트 IP가 아닌 프록시 
서버의 IP를 전달한다.
서버가 응답받은 IP는 프록시 서버의 IP이기 때문에 서버에게 클라이언트를 
숨길수 있다.


# Reverse Proxy
![](https://velog.velcdn.com/images/minthug94_/post/744049d6-76c7-4933-9476-72641be923ed/image.jpeg)

Reverse Proxy는 Forward와 반대로 서버 가까이에 위차한 프록시 서버를 
대신해서 클라이언트에 응답을 제공한다, 분산처리를 목적으로 하거나 보안을 
위해 프록시 서버를 이용한다

## 장점
- ### 분산처리
클라이언트 - 서버 구조에서 사용자가 많아져 서버에 과부하가 올 경우를 위해 
부하를 분산할 수 있다.
Reverse Proxy 구조에서 프록시 서버로 요청이 들어오면 여러 대의 서버로 
요청을 나누어 전달 후 처리한다.

- ### 보안
Forward 와 반대로 Reverse Proxy는 클라이언트에게 서버를 숨길 수 있다, 
클라이언트 입장에서의 요청을 보내는 서버가 프록시 서버가 되므로 실제 
서버의 IP주소가 노출 되지 않는다.

-----

# Load Balancer
서비스에 너무 많은 사용자가 접속하거나, 하나의 서버에 너무 많은 혹은 너무 
잦은 요청이 들어온다면 서버에는 과부하가 오게 된다.

![](https://velog.velcdn.com/images/minthug94_/post/5d8c334d-bd8b-4712-b09a-de468523c53f/image.png)

그래서 2가지 방법으로 문제를 해결하는 방법이 있다

## Scale-Up
스케일-업은 물리적으로 서버의 사양을 높이는 하드웨어적인 방법이다.
서버의 수를 늘리지 않고 프로그램 구현에 있어 변화가 필요없다는 장점을 
가지고있다.
하지만 서버의 사양을 높이는데 굉장히 높은 비용이 필요하고, 하드웨어의 
업그레이드엔 한계점이 존재하는 큰 단점을 안고있다.
근본적으로 업그레이드를 하더라도 클라이언트의 요청이 더 많아지면, 서버에 
발생하는 부하를 여전히 해결하지 못한다

## Scale-Out
스케일-아웃은 서버의 갯수를 늘려 하나의 서버에 줄 부하를 분산시키는 
방법이다.
많은 요청이 오더라도 여러대의 서버가 나눠서 처리하기 때문에 서버의 사양을 
높이지 않고도 비교적 저렴하게 부하를 해결하는 방법이다

스케일 아웃 방법으로 여러 대의 서버로 부하를 처리하는 경우, 
클라이언트로부터 온 요청을 여러 서버 중 어느 서버에 보내서 처리해야 할까?
요청을 여러 서버에 나눠 처리할 교통정리를 해줄 역할이 필요한데 이것이 바로 
로드 밸런서 이며, 여러 서버에 정리해주는 기술 혹은 프로그램을 로드 
밸런싱이라 한다.

### 로드 밸런서의 종류
- L2: 데이터 전송 계층에서 Mac 주소를 바탕으로 로드 밸런싱 한다.

- L3: 네트워크 계층에서 IP 주소를 바탕으로 로드 밸런싱 한다.

- L4: 전송 계층에서 IP주소와 Port를 바탕으로 로드 밸런싱 한다.

- L7: 응용 계층에서 클라이언트의 요청을 바탕으로 로드 밸런싱 한다.

---

# AutoScaling
## 오토스케일링이란?
서버의 과부하를 분산시키기 위해 로드 밸런싱을 사용하는데, 서버가 언제 
부하가 오고 언제 추가해야할지 사람이 쭉 지켜보다가 서버의 부하가 심해져 
제대로 된 서비스를 제공하지 못하는 순간까지 기다릴순 없으니 갑작스러운 
문제 등의 취약하다.
이런 상황을 오토스케일링을 통해 간편히 해결이 가능하다.

오토스케일링은 Scale-Out 방식으로 서버를 증설할 때 자동으로 서버를 
관리해주는 기능이다
클라이언트의 요청이 많아져 서버의 처리 요구량이 증가하면 새 리소스를 
자동으로 추가해주며, 반대의 상황 요구량이 적어지면 리소스를 감소시켜 
적절한 분산 환경을 만들어준다.

## 장점
- ### 동적 스케일링
오토스케일링의 가장 큰 장점은 사용자의 요구 수준에 따라 리소스를 동적으로 
스케일링 할 수 있다는 점이다.
스케일 업 할수있는 서버의 수에는 제한이 없고, 필요한 경우 서버 두 대에서 ~ 
수 만대의 서버로 즉시 스케일 업이 가능하다.

- ### 로드 밸런싱
리소스를 동적으로 스케일업 혹은 스케일-다운 한다, 로드 밸런서와 함께 
사용한다면 다수의 EC2 인스턴스에게 워크로드를 효과적으로 분배할 수 있어 
사용자가 정의한 규칙에 따라 워크로드를 효과적으로 관리 할 수 있다.

- ### 타겟 트래킹
사용자는 특정 타겟에 대해서만 오토스케일링을 할 수 있으며, 사용자가 설정한 
타겟에 맞춰 EC2 인스턴스의 수를 조정한다.

- ### 헬스 체크와 서버 플릿 관리
오토스케일링을 이용하면 EC2 인스턴스의 헬스 체크 상태를 모니터링 할 수 
있다.
만일 헬스 체크를 하는 과정에 특정 인스턴스에 문제가 감지되면, 자동으로 
다른 인스턴스로 교체한다.

> ### 다수의 EC2 서버에서 애플리케이션을 호스팅 하는 경우, 이들 이련의 EC2 
서버 집합을 AWS는 서버 플릿이라 부른다.
오토스케일링은 적정 수준의 서버 플릿 용량을 유지하는 데 도움을 준다
ex) 한 기업의 애플리케이션 6대의 EC2 서버에서 실행 중 일때 6대 서버에 대한 
헬스 체크 상태를 모니터링 하다가 특정 서버에 문제가 생기면 즉시 대응 
조치를 할 수 있다, 한 대 또는 그 이상의 서버가 다운 되면 오토스케일리은 
6대의 서버 인스턴스 처리 용량을 유지하기 위해 부족분 만큼의 서버를 추가로 
실행시키는 방식으로 서버 플릿을 유지한다.

